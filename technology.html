<!DOCTYPE html>
<html lang="en">
<head>
<nav></nav>
<script src="nav.js"></script>

 <link rel="stylesheet" href="style.css" />
  <meta charset="UTF-8">
  <title>Technology</title>
<style>
    body {
      color: white;
    }
    main {
      max-width: 1000px;
      margin: 40px auto;
      padding: 0 20px;
    }
    section {
      margin-bottom: 40px;
    }
    .image-container {
      text-align: center;
      margin: 30px 0;
    }
    .image-container img {
      width: 250px;
      max-width: 100%;
      height: auto;
      border: 1px solid #ccc;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    }
    ul {
      padding-left: 20px;
    }

  </style>
</head>
<body>
  <header>
    <h1>Technology Overview</h1>
  </header>
  <main>
    <section class="generic-box">
      <h2>Federated Telemetry Pipeline</h2>
      <p>
        TrustForgeAI integrates UEFI, OpenBMC, and Caliptra RoT to enable secure, scalable telemetry for federated AI workloads. The diagram below illustrates how platform events flow through firmware layers, are logged via Redfish schema extensions, and verified by federated trust controllers.
      </p>
</section>
<section>
      <div class="image-container">
        <img src="assets/telemetry-diagram.png" alt="Federated AI Telemetry Pipeline Diagram" />
      </div>
    </section>

    <section class="generic-box">
      <h2>Layered Security Architecture</h2>
      <p>
        Our platform security stack spans AI-enhanced runtime assurance, trusted display and connectivity protocols, and hardware-rooted trust. The diagram below illustrates this layered approach:
      </p>
</section>
<section>
      <div class="image-container">
        <img src="assets/security-stack.png" alt="AI-Enabled Security Stack Diagram" />
      </div>
      <ul>
        <li><strong>AI-Enabled Security:</strong> Runtime anomaly detection, model integrity enforcement</li>
        <li><strong>CXL | TDISP:</strong> Trusted interconnect and display protocols for secure data flow</li>
        <li><strong>PSA Level 3 | Caliptra RoT:</strong> Hardware-based attestation and cryptographic identity binding</li>
      </ul>
    </section>

    <section class="generic-box">
      <h2>Federated Learning for Runtime Security</h2>
      <p>
        We apply federated learning principles to platform security by distributing model updates and training signals across CPUs, GPUs, and BMCs. This architecture ensures secure, decentralized learning without exposing raw data.
      </p>
</section>
<section>
      <div class="image-container">
        <img src="assets/federated-learning-security.png" alt="Federated Learning Runtime Security Diagram" />
      </div>
      <ul>
        <li><strong>Model Update Distribution:</strong> Secure propagation of learned parameters across nodes</li>
        <li><strong>Training Signals:</strong> PCIe/CXL-based telemetry inputs for continuous learning</li>
        <li><strong>Platform RoT:</strong> Central trust anchor validating model integrity and telemetry authenticity</li>
      </ul>
    </section>
<section class="generic-box">
    <div class="faq-item">
        <h2>Federated AI Security model mapping to STRIDE</h2>

        <table class="summary-table">
            <thead>
                <tr>
                    <th>STRIDE Category</th>
                    <th>Federated AI Mapping</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>S – Spoofing</td>
                    <td>
                        Learns identity‑related anomalies from device attestation, boot measurements, 
                        and hardware‑rooted identity signals to detect fake devices, impersonation, 
                        and unauthorized access attempts.
                    </td>
                </tr>

                <tr>
                    <td>T – Tampering</td>
                    <td>
                        Models firmware, boot‑path, and configuration integrity patterns to detect 
                        unauthorized modifications, supply‑chain code injection, and below‑OS 
                        manipulation attempts.
                    </td>
                </tr>

                <tr>
                    <td>R – Repudiation</td>
                    <td>
                        Uses telemetry anchors and cryptographically validated event streams to learn 
                        deviations in auditability, missing logs, forged events, or attempts to erase 
                        operational traces.
                    </td>
                </tr>

                <tr>
                    <td>I – Information Disclosure</td>
                    <td>
                        Learns side‑channel and telemetry leakage patterns, detecting abnormal access 
                        to sensitive data, key‑handling anomalies, and unauthorized extraction behavior.
                    </td>
                </tr>

                <tr>
                    <td>D – Denial of Service</td>
                    <td>
                        Models resource‑usage baselines across CPU, memory, power, and boot flows to 
                        detect early‑boot DoS, flooding, starvation, and hardware‑level instability 
                        patterns.
                    </td>
                </tr>

                <tr>
                    <td>E – Elevation of Privilege</td>
                    <td>
                        Learns deviations in privilege transitions, secure‑boot bypass attempts, 
                        firmware escalation paths, and hardware‑level privilege abuse that OS‑level 
                        tools cannot observe.
                    </td>
                </tr>
            </tbody>
        </table>
    </div>
</section>

  </main>
  <footer>
    &copy; 2025 TrustForgeAI&trade;. All rights reserved.
  </footer>
</body>

</html>








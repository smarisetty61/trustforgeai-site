<!DOCTYPE html>
<html lang="en">
<head>
<nav>
     <a href="index.html">Home</a>
     <a href="about.html">About</a>
     <a href="products.html">Products</a>
     <a href="technology.html">Technology</a>
     <a href="ValueProp.html">Value Proposition</a>
     <a href="team.html">Team</a>
     <a href="contact.html">Contact</a>
     <a href="careers.html">Careers</a>
     <a href="news.html">News</a>
     <a href="faq.html">Faq</a>    </nav>
 <link rel="stylesheet" href="style.css" />
<title>FAQ </title>
  <style>
    body {
      color: #333;
    }

    main {
      max-width: 900px;
      margin: 40px auto;
      padding: 0 20px;
    }

    section {
      margin-bottom: 40px;
    }
  </style>

</head>
<body>
  <header>
    <h1>Frequently Asked Questions</h1>
  </header>
  <main>
      <section class="generic-box">
           <h2>What is Federated AI with a Low-Power MCU?</h2>
    <p>
        Federated AI with a low-power microcontroller (MCU) enables devices to learn from real-time 
        hardware, firmware, and sideband telemetry <strong>without exporting sensitive data off the device</strong>. 
        Instead of sending raw logs to the cloud, each MCU performs lightweight on-device learning, 
        shares only anonymized model updates, and receives aggregated improvements from the fleet.
    </p>
    <p>
        Because the learning runs on a <strong>low-power MCU</strong>, it fits within today’s platform constraints—
        minimal CPU, memory, and energy overhead—while still enabling below-OS threat detection. 
        The architecture also integrates seamlessly with existing platform standards such as secure 
        boot, attestation, and firmware update flows.
    </p>
    <p>
        As future MCU generations introduce <strong>dedicated AI acceleration and hardware learning primitives</strong>, 
        the same federated architecture automatically benefits from faster inference, richer models, 
        and further optimization of on-device detection and mitigation.
    </p>
 </section>
      <section class="generic-box">
        <h2>What is Caliptra and how does it enhance platform trust?</h2>
        <p>Caliptra is an open-source Root of Trust (RoT) IP block that provides cryptographic measurements, attestation, and identity binding for secure boot and runtime assurance. TrustForgeAI integrates Caliptra with OpenBMC and UEFI to enable federated trust across distributed AI platforms.</p>
      </section>

      <section class="generic-box">
        <h2>How does your platform support secure telemetry?</h2>
        <p>We use Redfish schema extensions, SPDM/EAT attestation, and telemetry anchors to stream verified platform events. These streams are policy-enforced and cryptographically validated to ensure runtime integrity.</p>
      </section>

      <section class="generic-box">
        <h2>What firmware layers do you support?</h2>
        <p>We support UEFI, OpenBMC, and Caliptra RoT integration. Our event schemas and telemetry pipelines span boot-time, runtime, and recovery flows across these layers.</p>
      </section>

      <section class="generic-box">
        <h2>Can your telemetry framework be integrated with existing cloud infrastructure?</h2>
        <p>Yes. Our telemetry anchors and Redfish extensions are cloud-agnostic and designed to integrate with Azure, AWS, and on-prem observability stacks.</p>
      </section>

      <section class="generic-box">
        <h2>What does the Federated AI Telemetry Framework include?</h2>
        <p>It includes schema templates, attestation pipelines, Redfish extensions, and visual dashboards for monitoring AI workload integrity and platform trust.</p>
      </section>

      <section class="generic-box">
        <h2>Do you offer consulting or integration support?</h2>
        <p>Yes. We provide strategic guidance, schema customization, and hands-on integration support for platform vendors, hyperscalers, and AI infrastructure teams.</p>
      </section>

      <section class="generic-box">
        <h2>How do I apply for a technical role?</h2>
        <p>Visit our <a href="/careers_1.html">Careers page</a> to view open positions and submit your application securely.</p>
      </section>

      <section class="generic-box">
        <h2>Are you open to industry collaborations?</h2>
        <p>Absolutely. We actively collaborate with standards bodies, silicon vendors, and cloud providers to advance platform assurance and federated trust.</p>
      </section>

      <section class="generic-box">
        <h2>What is Arm PSA and how does it relate to your platform?</h2>
        <p>Arm’s Platform Security Architecture (PSA) is a framework for designing and verifying secure IoT and embedded systems. TrustForgeAI aligns with PSA principles by integrating Caliptra RoT, secure boot, and attestation pipelines that support PSA certification and NIST 8259 compliance.</p>
      </section>

      <section class="generic-box">
        <h2>Do you support PSA Certified workflows?</h2>
        <p>Yes. Our platform architecture and event schemas are designed to support PSA Certified Level 1 and Level 2 workflows, including secure provisioning, firmware measurement, and runtime telemetry.</p>
      </section>
      <section class="generic-box">
<h2>What is threat modeling and how does it apply to this solution?</h2>
    <p>
        Threat modeling is the process of identifying and prioritizing how a system can be attacked. 
        For this solution, it ensures our federated AI focuses on the highest‑value firmware, hardware, 
        and sideband attack vectors—enabling accurate detection of below‑OS threats that OS‑level tools 
        miss. For a deeper overview, see 
        <a href="https://developer.arm.com/community/arm-community-blogs/b/internet-of-things-blog/posts/five-steps-to-successful-threat-modelling" 
           target="_blank">Five Steps to Successful Threat Modelling by Suresh Marisetty</a>.
    </p>
  </section>

<section class="generic-box">
    <div class="faq-item">
        <h2>How does the learning model for new threats map to static threat modeling?</h2>
        <p>
            Threat modeling defines the static attack surfaces and assets that matter most, and our 
            learning model builds on that foundation by continuously detecting real‑world deviations 
            along those same threat paths. In practice, the threat model defines <em>what to watch</em>, 
            and the federated AI learns <em>how those threats evolve</em>, allowing the system to adapt to 
            new below‑OS attack behaviors while staying aligned with the original security assumptions.
        </p>
    </div>
</section>

 <section class="generic-box">
<h2>How is Quantum readiness addressed?</h2>
    <p>
        Our solution is Quantum ready because its hardware‑anchored federated AI architecture 
        seamlessly adopts the orthogonal evolution of post‑quantum cryptography (PQC), ensuring 
        long‑term resilience as cryptographic standards transition to quantum‑safe algorithms.
    </p>
</section>
  </main>
  <footer>
    &copy; 2025 TrustForgeAI&trade;. All rights reserved.
  </footer>
</body>

</html>




